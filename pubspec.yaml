name: local_ai_chat
description: "Flutter chat app with offline AI using local LLM models"
publish_to: 'none'
version: 1.0.0+1

environment:
  sdk: ^3.10.4

dependencies:
  flutter:
    sdk: flutter

  cupertino_icons: ^1.0.8
  
  # LLM Inference - Currently using mock provider for iOS compatibility
  # To enable real LLM inference, uncomment and fix native setup:
  # flutter_llama: ^1.1.2
  
  # State Management
  provider: ^6.1.2
  
  # Local Storage
  hive: ^2.2.3
  hive_flutter: ^1.1.0
  
  # File & Path Management
  path_provider: ^2.1.4
  path: ^1.9.0
  
  # Network (for model download)
  dio: ^5.7.0
  
  # Utils
  uuid: ^4.5.1
  intl: ^0.19.0
  share_plus: ^10.1.4

dev_dependencies:
  flutter_test:
    sdk: flutter
  flutter_lints: ^6.0.0
  hive_generator: ^2.0.1
  build_runner: ^2.4.13

flutter:
  uses-material-design: true

  fonts:
    - family: Inter
      fonts:
        - asset: assets/fonts/Inter-Regular.ttf
          weight: 400
        - asset: assets/fonts/Inter-Medium.ttf
          weight: 500
        - asset: assets/fonts/Inter-SemiBold.ttf
          weight: 600
        - asset: assets/fonts/Inter-Bold.ttf
          weight: 700
